{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f422c8e5-b7c6-4f8a-9ff1-15bb0168140c",
   "metadata": {},
   "source": [
    "### Create a dataframe of jobs from the website realpython.github.io/fake-jobs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df745c37-dab2-4486-a6ee-9335bb2ee3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e8db609b-903b-4c55-a2f8-593593d4f73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02f0677b-bdec-4015-acd8-9de5352efda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://realpython.github.io/fake-jobs/'\n",
    "\n",
    "response = requests.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e3572cc-4b1b-423c-8087-31c6f8bd62e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d8577ec-6553-4216-9d1c-7c27b57ec5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "466803b2-a851-4f6c-9ca1-4b5d442955de",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BS(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9334cc41-bfc9-4785-9899-733eaa6705dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fake Python'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('title').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89421f9f-0367-46ed-8173-df0ba135ad3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Fake Python</title>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a31e8ba-24dc-4229-9b36-310f2dd9d322",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles = soup.find_all('h2', class_='title is-5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "490d808a-9192-4832-a902-cca3d10bb656",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles_list=[]\n",
    "for job in job_titles:\n",
    "    job_titles_list.append(job.get_text(strip=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb60cdcd-2ca1-4828-ae63-47116e901bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = soup.find_all('h3', class_='subtitle is-6 company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be09b019-2a97-4ad8-bfb4-b290812b4f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_list=[]\n",
    "for company in companies:\n",
    "        companies_list.append(company.get_text(strip=True))\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3479004d-23d4-4498-be48-49afeca721de",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = soup.find_all('p', class_='location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fa453aa-85d8-470d-b1b7-274d65faae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_list=[]\n",
    "for location in locations:\n",
    "    locations_list.append(location.get_text(strip=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9024ca15-6a99-4111-81ff-a314a5aa6de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates=soup.find_all('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e137b152-19e8-4301-9739-588a1e881d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_list=[]\n",
    "for date in dates:\n",
    "    dates_list.append(date['datetime'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ce26d7d-3ef0-4d71-a05f-a5e82b143033",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_jobs_df = pd.DataFrame({\n",
    "    'Job Title': job_titles_list,\n",
    "    'Company': companies_list,\n",
    "    'Location': locations_list,\n",
    "    'Date Posted': dates_list\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfaf6f05-f5ca-40f0-83ea-4e21b036d91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Date Posted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Python Developer</td>\n",
       "      <td>Payne, Roberts and Davis</td>\n",
       "      <td>Stewartbury, AA</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Energy engineer</td>\n",
       "      <td>Vasquez-Davidson</td>\n",
       "      <td>Christopherville, AA</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Legal executive</td>\n",
       "      <td>Jackson, Chambers and Levy</td>\n",
       "      <td>Port Ericaburgh, AA</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fitness centre manager</td>\n",
       "      <td>Savage-Bradley</td>\n",
       "      <td>East Seanview, AP</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Product manager</td>\n",
       "      <td>Ramirez Inc</td>\n",
       "      <td>North Jamieview, AP</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Museum/gallery exhibitions officer</td>\n",
       "      <td>Nguyen, Yoder and Petty</td>\n",
       "      <td>Lake Abigail, AE</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Radiographer, diagnostic</td>\n",
       "      <td>Holder LLC</td>\n",
       "      <td>Jacobshire, AP</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Database administrator</td>\n",
       "      <td>Yates-Ferguson</td>\n",
       "      <td>Port Susan, AE</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Furniture designer</td>\n",
       "      <td>Ortega-Lawrence</td>\n",
       "      <td>North Tiffany, AA</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Ship broker</td>\n",
       "      <td>Fuentes, Walls and Castro</td>\n",
       "      <td>Michelleville, AP</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Job Title                     Company  \\\n",
       "0              Senior Python Developer    Payne, Roberts and Davis   \n",
       "1                      Energy engineer            Vasquez-Davidson   \n",
       "2                      Legal executive  Jackson, Chambers and Levy   \n",
       "3               Fitness centre manager              Savage-Bradley   \n",
       "4                      Product manager                 Ramirez Inc   \n",
       "..                                 ...                         ...   \n",
       "95  Museum/gallery exhibitions officer     Nguyen, Yoder and Petty   \n",
       "96            Radiographer, diagnostic                  Holder LLC   \n",
       "97              Database administrator              Yates-Ferguson   \n",
       "98                  Furniture designer             Ortega-Lawrence   \n",
       "99                         Ship broker   Fuentes, Walls and Castro   \n",
       "\n",
       "                Location Date Posted  \n",
       "0        Stewartbury, AA  2021-04-08  \n",
       "1   Christopherville, AA  2021-04-08  \n",
       "2    Port Ericaburgh, AA  2021-04-08  \n",
       "3      East Seanview, AP  2021-04-08  \n",
       "4    North Jamieview, AP  2021-04-08  \n",
       "..                   ...         ...  \n",
       "95      Lake Abigail, AE  2021-04-08  \n",
       "96        Jacobshire, AP  2021-04-08  \n",
       "97        Port Susan, AE  2021-04-08  \n",
       "98     North Tiffany, AA  2021-04-08  \n",
       "99     Michelleville, AP  2021-04-08  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraped_jobs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40814561-ef13-414e-8f2c-25fabd09006c",
   "metadata": {},
   "source": [
    "#### Extract the job title for all jobs on this page. Store the results in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a8fbaeb-dd57-42d0-b185-1d0b13b365b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0n/96_jts790qb22y30bzlhgh_m0000gn/T/ipykernel_10822/3167425389.py:1: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  apply_urls = soup.find_all('a', class_='card-footer-item', text='Apply')\n"
     ]
    }
   ],
   "source": [
    "apply_urls = soup.find_all('a', class_='card-footer-item', text='Apply')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84c15951-92ee-440f-b614-07f66457fe84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://realpython.github.io/fake-jobs/jobs/senior-python-developer-0.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/energy-engineer-1.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/legal-executive-2.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/fitness-centre-manager-3.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/product-manager-4.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/medical-technical-officer-5.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/physiological-scientist-6.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/textile-designer-7.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/television-floor-manager-8.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/waste-management-officer-9.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/software-engineer-python-10.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/interpreter-11.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/architect-12.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/meteorologist-13.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/audiological-scientist-14.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/english-as-a-second-language-teacher-15.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/surgeon-16.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/equities-trader-17.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/newspaper-journalist-18.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/materials-engineer-19.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/python-programmer-entry-level-20.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/product-process-development-scientist-21.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/scientist-research-maths-22.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/ecologist-23.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/materials-engineer-24.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/historic-buildings-inspector-conservation-officer-25.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/data-scientist-26.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/psychiatrist-27.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/structural-engineer-28.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/immigration-officer-29.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/python-programmer-entry-level-30.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/neurosurgeon-31.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/broadcast-engineer-32.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/make-33.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/nurse-adult-34.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/air-broker-35.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/editor-film-video-36.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/production-assistant-radio-37.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/engineer-communications-38.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/sales-executive-39.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/software-developer-python-40.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/futures-trader-41.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/tour-manager-42.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/cytogeneticist-43.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/designer-multimedia-44.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/trade-union-research-officer-45.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/chemist-analytical-46.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/programmer-multimedia-47.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/engineer-broadcasting-operations-48.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/teacher-primary-school-49.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/python-developer-50.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/manufacturing-systems-engineer-51.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/producer-television-film-video-52.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/scientist-forensic-53.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/bonds-trader-54.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/editorial-assistant-55.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/photographer-56.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/retail-banker-57.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/jewellery-designer-58.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/ophthalmologist-59.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/back-end-web-developer-python-django-60.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/licensed-conveyancer-61.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/futures-trader-62.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/counselling-psychologist-63.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/insurance-underwriter-64.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/engineer-automotive-65.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/producer-radio-66.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/dispensing-optician-67.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/designer-fashion-clothing-68.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/chartered-loss-adjuster-69.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/back-end-web-developer-python-django-70.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/forest-woodland-manager-71.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/clinical-cytogeneticist-72.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/print-production-planner-73.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/systems-developer-74.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/graphic-designer-75.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/writer-76.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/field-seismologist-77.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/chief-strategy-officer-78.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/air-cabin-crew-79.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/python-programmer-entry-level-80.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/warden-ranger-81.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/sports-therapist-82.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/arts-development-officer-83.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/printmaker-84.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/health-and-safety-adviser-85.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/manufacturing-systems-engineer-86.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/programmer-applications-87.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/medical-physicist-88.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/media-planner-89.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/software-developer-python-90.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/surveyor-land-geomatics-91.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/legal-executive-92.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/librarian-academic-93.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/barrister-94.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/museum-gallery-exhibitions-officer-95.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/radiographer-diagnostic-96.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/database-administrator-97.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/furniture-designer-98.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/ship-broker-99.html']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_list=[]\n",
    "for url in apply_urls:\n",
    "   url_list.append(url['href'])\n",
    "url_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3218a50c-5cbc-45bb-a1fe-10979cdd5434",
   "metadata": {},
   "source": [
    "#### Get the job description text and URLs for each job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d584567a-a119-4d6c-8f40-8fd806a88609",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_job1 = 'https://realpython.github.io/fake-jobs/jobs/senior-python-developer-0.html'\n",
    "\n",
    "response2 = requests.get(URL_job1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bbbf5655-792f-4d25-87a3-c56a026dd44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2 = BS(response2.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b3df961-211f-4b92-957b-4785e4d5687a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n",
      "  <title>\n",
      "   Fake Python\n",
      "  </title>\n",
      "  <link href=\"https://cdn.jsdelivr.net/npm/bulma@0.9.2/css/bulma.min.css\" rel=\"stylesheet\"/>\n",
      " </head>\n",
      " <body>\n",
      "  <section class=\"section\">\n",
      "   <div class=\"container mb-5\">\n",
      "    <h1 class=\"title is-1\">\n",
      "     Fake Python\n",
      "    </h1>\n",
      "    <p class=\"subtitle is-3\">\n",
      "     Fake Jobs for Your Web Scraping Journey\n",
      "    </p>\n",
      "   </div>\n",
      "   <div class=\"container\">\n",
      "    <div class=\"columns is-multiline\" id=\"ResultsContainer\">\n",
      "     <div class=\"box\">\n",
      "      <h1 class=\"title is-2\">\n",
      "       Senior Python Developer\n",
      "      </h1>\n",
      "      <h2 class=\"subtitle is-4 company\">\n",
      "       Payne, Roberts and Davis\n",
      "      </h2>\n",
      "      <div class=\"content\">\n",
      "       <p>\n",
      "        Professional asset web application environmentally friendly detail-oriented asset. Coordinate educational dashboard agile employ growth opportunity. Company programs CSS explore role. Html educational grit web application. Oversea SCRUM talented support. Web Application fast-growing communities inclusive programs job CSS. Css discussions growth opportunity explore open-minded oversee. Css Python environmentally friendly collaborate inclusive role. Django no experience oversee dashboard environmentally friendly willing to learn programs. Programs open-minded programs asset.\n",
      "       </p>\n",
      "       <p id=\"location\">\n",
      "        <strong>\n",
      "         Location:\n",
      "        </strong>\n",
      "        Stewartbury, AA\n",
      "       </p>\n",
      "       <p id=\"date\">\n",
      "        <strong>\n",
      "         Posted:\n",
      "        </strong>\n",
      "        2021-04-08\n",
      "       </p>\n",
      "      </div>\n",
      "     </div>\n",
      "    </div>\n",
      "   </div>\n",
      "  </section>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup2.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0dd1e2fa-fd77-4c59-883c-5dde9c19cb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_div = soup2.find('div',class_='content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "206db5df-d46b-4d0f-9e5b-8f827f989919",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description = content_div.find('p').get_text(strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24ea1df6-da21-4bf4-aeaf-97e88cf89e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_description(url):\n",
    "    response = requests.get(url)\n",
    "    soup=BS(response.text)\n",
    "    content_div = soup.find('div',class_='content')\n",
    "    job_description = content_div.find('p').get_text(strip=True)\n",
    "    return job_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "018546f3-a96b-4789-82aa-1027dca5c900",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_desc= url_description('https://realpython.github.io/fake-jobs/jobs/television-floor-manager-8.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b7e3a40-c1a1-42d7-b5ee-ce84f8146337",
   "metadata": {},
   "outputs": [],
   "source": [
    "description=[]\n",
    "for url in url_list:\n",
    "    job_desc= url_description(url)\n",
    "    description.append(job_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38cf2a5f-d64a-4182-b0ae-d7dca8beee71",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_jobs_df['URL'] = url_list\n",
    "scraped_jobs_df['Description'] = description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e290686-fec6-4a7c-ba23-f8f9b9260351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Date Posted</th>\n",
       "      <th>URL</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Python Developer</td>\n",
       "      <td>Payne, Roberts and Davis</td>\n",
       "      <td>Stewartbury, AA</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/se...</td>\n",
       "      <td>Professional asset web application environment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Energy engineer</td>\n",
       "      <td>Vasquez-Davidson</td>\n",
       "      <td>Christopherville, AA</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/en...</td>\n",
       "      <td>Party prevent live. Quickly candidate change a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Legal executive</td>\n",
       "      <td>Jackson, Chambers and Levy</td>\n",
       "      <td>Port Ericaburgh, AA</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/le...</td>\n",
       "      <td>Administration even relate head color. Staff b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fitness centre manager</td>\n",
       "      <td>Savage-Bradley</td>\n",
       "      <td>East Seanview, AP</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/fi...</td>\n",
       "      <td>Tv program actually race tonight themselves tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Product manager</td>\n",
       "      <td>Ramirez Inc</td>\n",
       "      <td>North Jamieview, AP</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/pr...</td>\n",
       "      <td>Traditional page a although for study anyone. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Museum/gallery exhibitions officer</td>\n",
       "      <td>Nguyen, Yoder and Petty</td>\n",
       "      <td>Lake Abigail, AE</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/mu...</td>\n",
       "      <td>Paper age physical current note. There reality...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Radiographer, diagnostic</td>\n",
       "      <td>Holder LLC</td>\n",
       "      <td>Jacobshire, AP</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/ra...</td>\n",
       "      <td>Able such right culture. Wrong pick structure ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Database administrator</td>\n",
       "      <td>Yates-Ferguson</td>\n",
       "      <td>Port Susan, AE</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/da...</td>\n",
       "      <td>Create day party decade high clear. Past trade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Furniture designer</td>\n",
       "      <td>Ortega-Lawrence</td>\n",
       "      <td>North Tiffany, AA</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/fu...</td>\n",
       "      <td>Pressure under rock next week. Recognize so re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Ship broker</td>\n",
       "      <td>Fuentes, Walls and Castro</td>\n",
       "      <td>Michelleville, AP</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/sh...</td>\n",
       "      <td>Management common popular project only. Must s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Job Title                     Company  \\\n",
       "0              Senior Python Developer    Payne, Roberts and Davis   \n",
       "1                      Energy engineer            Vasquez-Davidson   \n",
       "2                      Legal executive  Jackson, Chambers and Levy   \n",
       "3               Fitness centre manager              Savage-Bradley   \n",
       "4                      Product manager                 Ramirez Inc   \n",
       "..                                 ...                         ...   \n",
       "95  Museum/gallery exhibitions officer     Nguyen, Yoder and Petty   \n",
       "96            Radiographer, diagnostic                  Holder LLC   \n",
       "97              Database administrator              Yates-Ferguson   \n",
       "98                  Furniture designer             Ortega-Lawrence   \n",
       "99                         Ship broker   Fuentes, Walls and Castro   \n",
       "\n",
       "                Location Date Posted  \\\n",
       "0        Stewartbury, AA  2021-04-08   \n",
       "1   Christopherville, AA  2021-04-08   \n",
       "2    Port Ericaburgh, AA  2021-04-08   \n",
       "3      East Seanview, AP  2021-04-08   \n",
       "4    North Jamieview, AP  2021-04-08   \n",
       "..                   ...         ...   \n",
       "95      Lake Abigail, AE  2021-04-08   \n",
       "96        Jacobshire, AP  2021-04-08   \n",
       "97        Port Susan, AE  2021-04-08   \n",
       "98     North Tiffany, AA  2021-04-08   \n",
       "99     Michelleville, AP  2021-04-08   \n",
       "\n",
       "                                                  URL  \\\n",
       "0   https://realpython.github.io/fake-jobs/jobs/se...   \n",
       "1   https://realpython.github.io/fake-jobs/jobs/en...   \n",
       "2   https://realpython.github.io/fake-jobs/jobs/le...   \n",
       "3   https://realpython.github.io/fake-jobs/jobs/fi...   \n",
       "4   https://realpython.github.io/fake-jobs/jobs/pr...   \n",
       "..                                                ...   \n",
       "95  https://realpython.github.io/fake-jobs/jobs/mu...   \n",
       "96  https://realpython.github.io/fake-jobs/jobs/ra...   \n",
       "97  https://realpython.github.io/fake-jobs/jobs/da...   \n",
       "98  https://realpython.github.io/fake-jobs/jobs/fu...   \n",
       "99  https://realpython.github.io/fake-jobs/jobs/sh...   \n",
       "\n",
       "                                          Description  \n",
       "0   Professional asset web application environment...  \n",
       "1   Party prevent live. Quickly candidate change a...  \n",
       "2   Administration even relate head color. Staff b...  \n",
       "3   Tv program actually race tonight themselves tr...  \n",
       "4   Traditional page a although for study anyone. ...  \n",
       "..                                                ...  \n",
       "95  Paper age physical current note. There reality...  \n",
       "96  Able such right culture. Wrong pick structure ...  \n",
       "97  Create day party decade high clear. Past trade...  \n",
       "98  Pressure under rock next week. Recognize so re...  \n",
       "99  Management common popular project only. Must s...  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraped_jobs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e29b31f-8d55-413f-9684-45c6be10f295",
   "metadata": {},
   "source": [
    "#### Next, get those same urls in a different way. Examine the urls and see if you can spot the pattern of how they are constructed. Then, build the url using the elements you have already extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44cc0b31-0361-4809-8c3e-c18a9f3ea9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://realpython.github.io/fake-jobs/jobs/senior-python-developer-0.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/energy-engineer-1.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/legal-executive-2.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/fitness-centre-manager-3.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/product-manager-4.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/medical-technical-officer-5.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/physiological-scientist-6.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/textile-designer-7.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/television-floor-manager-8.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/waste-management-officer-9.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/software-engineer-python-10.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/interpreter-11.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/architect-12.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/meteorologist-13.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/audiological-scientist-14.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/english-as-a-second-language-teacher-15.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/surgeon-16.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/equities-trader-17.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/newspaper-journalist-18.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/materials-engineer-19.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/python-programmer-entry-level-20.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/product-process-development-scientist-21.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/scientist-research-maths-22.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/ecologist-23.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/materials-engineer-24.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/historic-buildings-inspector-conservation-officer-25.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/data-scientist-26.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/psychiatrist-27.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/structural-engineer-28.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/immigration-officer-29.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/python-programmer-entry-level-30.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/neurosurgeon-31.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/broadcast-engineer-32.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/make-33.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/nurse-adult-34.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/air-broker-35.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/editor-film-video-36.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/production-assistant-radio-37.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/engineer-communications-38.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/sales-executive-39.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/software-developer-python-40.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/futures-trader-41.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/tour-manager-42.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/cytogeneticist-43.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/designer-multimedia-44.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/trade-union-research-officer-45.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/chemist-analytical-46.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/programmer-multimedia-47.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/engineer-broadcasting-operations-48.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/teacher-primary-school-49.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/python-developer-50.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/manufacturing-systems-engineer-51.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/producer-television-film-video-52.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/scientist-forensic-53.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/bonds-trader-54.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/editorial-assistant-55.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/photographer-56.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/retail-banker-57.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/jewellery-designer-58.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/ophthalmologist-59.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/back-end-web-developer-python-django-60.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/licensed-conveyancer-61.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/futures-trader-62.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/counselling-psychologist-63.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/insurance-underwriter-64.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/engineer-automotive-65.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/producer-radio-66.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/dispensing-optician-67.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/designer-fashion-clothing-68.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/chartered-loss-adjuster-69.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/back-end-web-developer-python-django-70.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/forest-woodland-manager-71.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/clinical-cytogeneticist-72.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/print-production-planner-73.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/systems-developer-74.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/graphic-designer-75.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/writer-76.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/field-seismologist-77.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/chief-strategy-officer-78.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/air-cabin-crew-79.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/python-programmer-entry-level-80.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/warden-ranger-81.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/sports-therapist-82.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/arts-development-officer-83.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/printmaker-84.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/health-and-safety-adviser-85.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/manufacturing-systems-engineer-86.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/programmer-applications-87.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/medical-physicist-88.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/media-planner-89.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/software-developer-python-90.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/surveyor-land-geomatics-91.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/legal-executive-92.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/librarian-academic-93.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/barrister-94.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/museum-gallery-exhibitions-officer-95.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/radiographer-diagnostic-96.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/database-administrator-97.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/furniture-designer-98.html',\n",
       " 'https://realpython.github.io/fake-jobs/jobs/ship-broker-99.html']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_list2=[]\n",
    "i=0\n",
    "for job in job_titles_list:\n",
    "    job=job.lower()\n",
    "    if ', ' in job:\n",
    "        job = job.replace(', ', '-')\n",
    "    if ' (' in job:\n",
    "        job = job.replace(' (', '-')\n",
    "    if '/' in job:\n",
    "        job = job.replace('/', '-')\n",
    "    if ')' in job:\n",
    "        job = job.replace(')', '')\n",
    "    if ' ' in job:\n",
    "        job= job.replace(' ', '-')\n",
    "    url='https://realpython.github.io/fake-jobs/jobs/'+job+'-'+str(i)+'.html'\n",
    "    i=i+1\n",
    "    url_list2.append(url)\n",
    "url_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ad0641a-7c54-4987-9f74-eb5b13d64ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_list2==url_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bd1901-6fec-489e-ad11-6bc4a9c84d3c",
   "metadata": {},
   "source": [
    "# Bonus Questions\n",
    "### Navigate to https://www.billboard.com/charts/hot-100/. Using BeautifulSoup, extract out the This Week, artist, song, Last Week, Peak Position, and Weeks on Chart values into a pandas DataFrame. \n",
    "Hint: The HTML for the number one ranked song is slightly different from that of the rest of the songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc59f7af-b28a-450a-aa56-62712b743f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.billboard.com/charts/hot-100/'\n",
    "\n",
    "response = requests.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "84ac4ffa-c0aa-444f-903c-3e9bd70141b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BS(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aacb1a2e-0c11-4ae9-bebd-2882d7b2cd40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.ResultSet"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_week = soup.find_all('span', class_='c-label a-font-primary-bold-l u-font-size-32@tablet u-letter-spacing-0080@tablet')\n",
    "type(this_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1e08011-2be1-40f3-9f94-027a987ebf50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_week_list=[]\n",
    "for span in this_week:\n",
    "    text = span.text.strip()  \n",
    "    this_week_list.append(text)\n",
    "len(this_week_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1bded4b-cf34-4073-9e57-1888bbfa3841",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs=soup.find_all('h3',class_=\"c-title a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 lrv-u-font-size-18@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-330 u-max-width-230@tablet-only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0bdc5b1e-1de9-4302-b84a-18efc2a097f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_list=[]\n",
    "for song in songs:\n",
    "    text = song.text.strip()  \n",
    "    song_list.append(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "709306df-670f-4fbf-8d7b-6085d8abc6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Bar Song (Tipsy)'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_song = soup.find_all('h3', class_='c-title')\n",
    "first_song_list = []\n",
    "\n",
    "for song in first_song:\n",
    "    text = song.get_text(strip=True)  \n",
    "    first_song_list.append(text)\n",
    "\n",
    "first_song_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f850b4f2-4473-4bb5-9cd5-6c5d29f42b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_list.insert(0, first_song_list[0])\n",
    "len(song_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "088622e7-37f8-4a30-9e65-e46d44c53289",
   "metadata": {},
   "outputs": [],
   "source": [
    "singers=soup.find_all('span',class_=\"c-label a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a3960f2c-2296-4618-884f-6ef27aba2942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singer_list=[]\n",
    "for singer in singers:\n",
    "    text = singer.text.strip()  \n",
    "    singer_list.append(text) \n",
    "len(singer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "72ccad30-b8c3-42b3-a474-67397ad0ca4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shaboozey'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_singer = soup.find_all('span', class_='c-label')\n",
    "first_singer_list = []\n",
    "\n",
    "for singer in first_singer:\n",
    "    text = singer.get_text(strip=True) \n",
    "    first_singer_list.append(text)\n",
    "\n",
    "first_singer_list[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0fd4c56a-e513-4819-919a-d86d2ba554e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singer_list.insert(0, first_singer_list[4])\n",
    "len(singer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d090b323-85e3-4461-9b5a-d91bf0e05e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "li_elements = soup.find_all('li',class_=\"o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max lrv-u-flex-grow-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cfe951fe-a52d-456d-8ca6-7643bd9fc10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "li_list=[]\n",
    "for li in li_elements:\n",
    "    text = li.text.strip()  \n",
    "    li_list.append(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "903fe6e6-7f41-4538-bc0c-432e3ac3e42f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_week_list=[]\n",
    "for i in range(len(li_list)):\n",
    "    if i % 2 == 0:  \n",
    "        last_week_list.append(li_list[i])\n",
    "len(last_week_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8914cb22-90d1-4be7-ac65-3835bed9b943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weeks_onchart_list=[]\n",
    "for i in range(len(li_list)):\n",
    "    if i % 2 != 0:  \n",
    "        weeks_onchart_list.append(li_list[i])\n",
    "len(weeks_onchart_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a5ffae53-c0e1-4ed7-9c35-98a0d1f198be",
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks= soup.find_all('li',class_=\"o-chart-results-list__item // a-chart-bg-color a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-background-color-grey-lightest lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light lrv-u-flex-grow-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aa547193-a06b-4350-96f4-a6ef9ba3f7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_position_list=[]\n",
    "for peak in peaks:\n",
    "   text = peak.get_text(strip=True)\n",
    "   peak_position_list.append(text) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "567d1afc-c6c7-4961-ab4d-4d30447fd849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_position_list_final=[]\n",
    "for i in range(len(peak_position_list)):\n",
    "    if i % 2 != 0:  \n",
    "       peak_position_list_final.append(peak_position_list[i])\n",
    "len(peak_position_list_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1b09d8a5-05c4-4dac-b509-511c90b80de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>This week rank</th>\n",
       "      <th>Song</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Last week rank</th>\n",
       "      <th>Peak pos</th>\n",
       "      <th>Wks on chart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A Bar Song (Tipsy)</td>\n",
       "      <td>Shaboozey</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>I Had Some Help</td>\n",
       "      <td>Post Malone Featuring Morgan Wallen</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Not Like Us</td>\n",
       "      <td>Kendrick Lamar</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Million Dollar Baby</td>\n",
       "      <td>Tommy Richman</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Espresso</td>\n",
       "      <td>Sabrina Carpenter</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Bass Boat</td>\n",
       "      <td>Zach Bryan</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Think I'm In Love With You</td>\n",
       "      <td>Chris Stapleton</td>\n",
       "      <td>87</td>\n",
       "      <td>49</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Beautiful As You</td>\n",
       "      <td>Thomas Rhett</td>\n",
       "      <td>95</td>\n",
       "      <td>83</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Sweet Dreams</td>\n",
       "      <td>Koe Wetzel</td>\n",
       "      <td>88</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>Sandpaper</td>\n",
       "      <td>Zach Bryan Featuring Bruce Springsteen</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   This week rank                        Song  \\\n",
       "0               1          A Bar Song (Tipsy)   \n",
       "1               2             I Had Some Help   \n",
       "2               3                 Not Like Us   \n",
       "3               4         Million Dollar Baby   \n",
       "4               5                    Espresso   \n",
       "..            ...                         ...   \n",
       "95             96                   Bass Boat   \n",
       "96             97  Think I'm In Love With You   \n",
       "97             98            Beautiful As You   \n",
       "98             99                Sweet Dreams   \n",
       "99            100                   Sandpaper   \n",
       "\n",
       "                                    Artist Last week rank Peak pos  \\\n",
       "0                                Shaboozey              2        1   \n",
       "1      Post Malone Featuring Morgan Wallen              3        1   \n",
       "2                           Kendrick Lamar              1        1   \n",
       "3                            Tommy Richman              4        2   \n",
       "4                        Sabrina Carpenter              5        3   \n",
       "..                                     ...            ...      ...   \n",
       "95                              Zach Bryan             61       61   \n",
       "96                         Chris Stapleton             87       49   \n",
       "97                            Thomas Rhett             95       83   \n",
       "98                              Koe Wetzel             88       35   \n",
       "99  Zach Bryan Featuring Bruce Springsteen             71       71   \n",
       "\n",
       "   Wks on chart  \n",
       "0            14  \n",
       "1            10  \n",
       "2            11  \n",
       "3            12  \n",
       "4            14  \n",
       "..          ...  \n",
       "95            2  \n",
       "96           11  \n",
       "97            6  \n",
       "98            9  \n",
       "99            2  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billboard_df = pd.DataFrame({\n",
    "    'This week rank': this_week_list,\n",
    "    'Song': song_list,\n",
    "    'Artist': singer_list,\n",
    "    'Last week rank': last_week_list,\n",
    "    'Peak pos': peak_position_list_final,\n",
    "    'Wks on chart': weeks_onchart_list\n",
    "})\n",
    "billboard_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec569c1-45ef-4ba4-bdc5-9e293bff73ca",
   "metadata": {},
   "source": [
    "### Write a function which will, given a date, return a pandas DataFrame containing the Billboard chart data for that date.\n",
    "Navigate to last week's chart. Notice how the url for the page changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "99361670-fd2b-445e-bdcc-a6d67629cb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import pandas as pd\n",
    "\n",
    "def billboard_df_date(date):\n",
    "    \"\"\"\n",
    "    Creates a DataFrame of the top 100 Billboard songs for a given date.\n",
    "    Date should be in the string format 'YYYY-MM-DD'.\n",
    "    \"\"\"\n",
    "    url = f'https://www.billboard.com/charts/hot-100/{date}/'\n",
    "    response_new = requests.get(url)\n",
    "    \n",
    "    if response_new.status_code != 200:\n",
    "        print(f\"Failed to retrieve data for {date}. Status code: {response_new.status_code}\")\n",
    "        return pd.DataFrame()  \n",
    "    \n",
    "    soup_new = BS(response_new.text, 'html.parser')\n",
    "    \n",
    "    # this week's ranks\n",
    "    this_week_new = soup_new.find_all('span', class_='c-label a-font-primary-bold-l u-font-size-32@tablet u-letter-spacing-0080@tablet')\n",
    "    this_week_list_new = [span.text.strip() for span in this_week_new]\n",
    "\n",
    "    # song titles\n",
    "    songs_new = soup_new.find_all('h3', class_=\"c-title a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 lrv-u-font-size-18@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-330 u-max-width-230@tablet-only\")\n",
    "    song_list_new = [song.get_text(strip=True) for song in songs_new]\n",
    "\n",
    "\n",
    "    # Insert the first song \n",
    "    if song_list_new:\n",
    "        first_song_new = song_list_new[0]\n",
    "        song_list_new.insert(0, first_song_new)\n",
    "\n",
    "    \n",
    "    #  artist names\n",
    "    singers_new = soup_new.find_all('span', class_=\"c-label a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only\")\n",
    "    singer_list_new = [singer.text.strip() for singer in singers_new]\n",
    "\n",
    "\n",
    "    # edge case for empty first_singer_list_new\n",
    "    if len(singer_list_new) >= 5:\n",
    "        singer_list_new.insert(0, singer_list_new[4]) \n",
    "\n",
    "    \n",
    "    #  last week ranks and weeks on chart\n",
    "    li_elements_new = soup_new.find_all('li', class_=\"o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max lrv-u-flex-grow-1\")\n",
    "    li_list_new = [li.text.strip() for li in li_elements_new]\n",
    "\n",
    "    last_week_list_new = li_list_new[::2]  # Every second element\n",
    "    weeks_onchart_list_new = li_list_new[1::2]  # Every other element\n",
    "\n",
    "    # peak positions\n",
    "    peaks_new = soup_new.find_all('li', class_=\"o-chart-results-list__item // a-chart-bg-color a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-background-color-grey-lightest lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light lrv-u-flex-grow-1\")\n",
    "    peak_position_list_new = [peak.get_text(strip=True) for peak in peaks_new]\n",
    "\n",
    "    peak_position_list_final_new = peak_position_list_new[1::2]  # Peak positions\n",
    "\n",
    "    # Creating the DataFrame\n",
    "    billboard_df_new = pd.DataFrame({\n",
    "        'This week rank': this_week_list_new,\n",
    "        'Song': song_list_new,\n",
    "        'Artist': singer_list_new,\n",
    "        'Last week rank': last_week_list_new,\n",
    "        'Peak pos': peak_position_list_final_new,\n",
    "        'Wks on chart': weeks_onchart_list_new\n",
    "    })\n",
    "\n",
    "    return billboard_df_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "a6518799-35f8-4a28-8599-b82705bfe1ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>This week rank</th>\n",
       "      <th>Song</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Last week rank</th>\n",
       "      <th>Peak pos</th>\n",
       "      <th>Wks on chart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A Bar Song (Tipsy)</td>\n",
       "      <td>Sabrina Carpenter</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A Bar Song (Tipsy)</td>\n",
       "      <td>Shaboozey</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>I Had Some Help</td>\n",
       "      <td>Post Malone Featuring Morgan Wallen</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Million Dollar Baby</td>\n",
       "      <td>Tommy Richman</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Espresso</td>\n",
       "      <td>Sabrina Carpenter</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>After Hours</td>\n",
       "      <td>Kehlani</td>\n",
       "      <td>84</td>\n",
       "      <td>72</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Lithonia</td>\n",
       "      <td>Childish Gambino</td>\n",
       "      <td>-</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Belong Together</td>\n",
       "      <td>Mark Ambor</td>\n",
       "      <td>92</td>\n",
       "      <td>74</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Funny Man</td>\n",
       "      <td>Zach Bryan</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>Okay</td>\n",
       "      <td>JT</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   This week rank                 Song                               Artist  \\\n",
       "0               1   A Bar Song (Tipsy)                    Sabrina Carpenter   \n",
       "1               2   A Bar Song (Tipsy)                            Shaboozey   \n",
       "2               3      I Had Some Help  Post Malone Featuring Morgan Wallen   \n",
       "3               4  Million Dollar Baby                        Tommy Richman   \n",
       "4               5             Espresso                    Sabrina Carpenter   \n",
       "..            ...                  ...                                  ...   \n",
       "95             96          After Hours                              Kehlani   \n",
       "96             97             Lithonia                     Childish Gambino   \n",
       "97             98      Belong Together                           Mark Ambor   \n",
       "98             99            Funny Man                           Zach Bryan   \n",
       "99            100                 Okay                                   JT   \n",
       "\n",
       "   Last week rank Peak pos Wks on chart  \n",
       "0               3        1           10  \n",
       "1               1        1           13  \n",
       "2               2        1            9  \n",
       "3               5        2           11  \n",
       "4               4        3           13  \n",
       "..            ...      ...          ...  \n",
       "95             84       72            7  \n",
       "96              -       97            1  \n",
       "97             92       74           11  \n",
       "98              -       99            1  \n",
       "99             72       72            3  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billboard_df_date('2024-07-20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f216210-7cf1-4173-9547-58a8ff7444d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
